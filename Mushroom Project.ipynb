{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mushroom Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "df = pd.read_csv('agaricus-lepiota.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot infer any information looking at the dataset since the columns data are encoded. we will have to see \n",
    "each coolumn and give a proper name as per the data present in the column. we will refer agaricus-lepiota.names \n",
    "present in the UCI repository.\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique values in column p\n",
    "df['p'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In column p it is classified that if the mushroom is edible or poisonous as per the information avaialable in the UCI repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'p':'class'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let us also label encode the column class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(df['class'])\n",
    "print(encoder.classes_)\n",
    "df['class'] = encoder.transform(df['class'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the column 'class' 0 is encoded as Edible and 1 is encoded as Poison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the rest columns and from the information from the UCI repository we can see that the lables in the data represent the color, structure, place where grown etc of the mushrooms. All the columns are catogorical so lets encode then to convert into numerical one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since p.2 have only one value p (0 after encoding) we can drop it as it will not affect our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['p.2'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of columns to be converted into the numerical varibale\n",
    "cols=['x', 's', 'n', 't', 'p.1', 'f', 'c', 'n.1', 'k', 'e', 'e.1','s.1', 's.2', 'w', 'w.1', 'w.2', \n",
    "      'o', 'p.3', 'k.1', 's.3', 'u']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using for loop we will pass each column and encode it.\n",
    "for i in range(len(cols)):\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(df[cols[i]])\n",
    "    df[cols[i]] = encoder.transform(df[cols[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "plt.figure(figsize=(20,15))\n",
    "sns.heatmap(corr,vmax=0.6, square=True,annot=True,fmt='.2f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns which shows very less correlation with the class column are:\n",
    "'x','n'\n",
    "Hence, we can remove these columns from our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.drop(['x','n'],axis=1)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us check the correltation plot once again to verify we have all the columns which are correlated to the\n",
    "#target column class\n",
    "corr = df_new.corr()\n",
    "plt.figure(figsize=(20,15))\n",
    "sns.heatmap(corr,vmax=1,linecolor='black',linewidths=0.5,square=True,annot=True,fmt='.2f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the dataset into x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_new.drop(['class'], axis=1)\n",
    "y = df_new['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the best random state\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "best_rstate=0\n",
    "accu=0\n",
    "\n",
    "for i in range(30,200):\n",
    "    x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.25,random_state=i)\n",
    "    mod=LogisticRegression()\n",
    "    mod.fit(x_train,y_train)\n",
    "    y_pred = mod.predict(x_test)\n",
    "    tempaccu=accuracy_score(y_test,y_pred)\n",
    "    if tempaccu > accu:\n",
    "        accu = tempaccu\n",
    "        best_rstate = i\n",
    "        \n",
    "print(f\"Best Accuracy {accu*100} found on Random state {best_rstate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found the best random state at 121 with Best Accuracy of 96.1% and will be using it in train_test_split in next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating train test split using the best random state which we found above\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.2,random_state=121)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Classification libraries for model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = [LogisticRegression,RandomForestClassifier,SGDClassifier,DecisionTreeClassifier,\n",
    "        KNeighborsClassifier,GaussianNB]\n",
    "\n",
    "for each in algo:\n",
    "    model = each()\n",
    "    model.fit(x_train,y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(f\"{model}\\n\",classification_report(y_test, y_pred))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression has good accuracy score of 96%, so we will go for LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating parameter list to pass in GridSearchCV\n",
    "parameters = {\"max_iter\" : [500,700,900,1100,1300,1500],\n",
    "              \"penalty\" : [\"elasticnet\",\"l1\",\"l2\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "GCV = GridSearchCV(LogisticRegression(),parameters,cv=5,scoring='r2') # initializing GridsearchCV\n",
    "GCV.fit(x_train,y_train)\n",
    "GCV.best_estimator_   # Finding best estimators\n",
    "GCV_pred = GCV.best_estimator_.predict(x_test) #predicting the values using best estimators found by gridserchcv\n",
    "print(\"Final Accuracy: \",accuracy_score(y_test,GCV_pred)*100) # final accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
