{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict A Doctor's Consultation Fee "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have all been in situation where we go to a doctor in emergency and find that the consultation fees are too high. As a data scientist we all should do better. What if you have data that records important details about a doctor and you get to build a model to predict the doctorâ€™s consulting fee.? This is the hackathon that lets you do that.\n",
    "\n",
    "\n",
    "\n",
    "Size of training set: 5961 records\n",
    "\n",
    "\n",
    "Size of test set: 1987 records\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURES:\n",
    "\n",
    "\n",
    "Qualification: Qualification and degrees held by the doctor\n",
    "\n",
    "\n",
    "Experience: Experience of the doctor in number of years\n",
    "\n",
    "\n",
    "Rating: Rating given by patients\n",
    "\n",
    "\n",
    "Profile: Type of the doctor\n",
    "\n",
    "\n",
    "Miscellaeous_Info: Extra information about the doctor\n",
    "\n",
    "\n",
    "Fees: Fees charged by the doctor\n",
    "\n",
    "\n",
    "Place: Area and the city where the doctor is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy and Pandas library import for analysis of the dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the datset\n",
    "\n",
    "Final_Test = pd.read_excel('Final_Test.xlsx')\n",
    "Final_Train = pd.read_excel('Final_Train.xlsx')\n",
    "Sample_submission = pd.read_excel('Sample_submission.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape for each Dataframe\n",
    "\n",
    "print(\"Final_Train:\", Final_Train.shape)\n",
    "print(\"Final_Test:\", Final_Test.shape)\n",
    "print(\"Sample_submission:\", Sample_submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial 5 rows of data for Final_Train\n",
    "\n",
    "Final_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial 5 rows of data for Final_Test\n",
    "\n",
    "Final_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the columns into list\n",
    "\n",
    "list_Final_Test=list(Final_Test.columns)\n",
    "list_Final_Train=list(Final_Train.columns)\n",
    "list_Sample_submission=list(Sample_submission.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** General Information **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ****************** Checking Null Values ******************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have null values in the columns: Rating, Place, Miscellaneous_Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have null values in the columns: Rating, Place, Miscellaneous_Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** Unique values check **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Final_Train\\n')\n",
    "print('Qualification:', Final_Train['Qualification'].nunique())\n",
    "print('Experience:', Final_Train['Experience'].nunique())\n",
    "print('Rating:', Final_Train['Rating'].nunique())\n",
    "print('Place:', Final_Train['Place'].nunique())\n",
    "print('Profile', Final_Train['Profile'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Final_Test\\n')\n",
    "print('Qualification:', Final_Test['Qualification'].nunique())\n",
    "print('Experience:', Final_Test['Experience'].nunique())\n",
    "print('Rating:', Final_Test['Rating'].nunique())\n",
    "print('Place:', Final_Test['Place'].nunique())\n",
    "print('Profile', Final_Test['Profile'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the 'years experiece' part from the Experience column in both Final_Train and Final_Test dataframe.\n",
    "# We will keep only integer value and convert the column data type to int\n",
    "# Since Experience column does not have null values, hence we will keep this column as is for now.\n",
    "\n",
    "Final_Train['Experience'] = Final_Train['Experience'].str.replace('years experience','').astype(int)\n",
    "Final_Train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Test['Experience'] = Final_Test['Experience'].str.replace('years experience','').astype(int)\n",
    "Final_Test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have replaced the mising values with -99% to differentiate them.\n",
    "# We will omit the % sign in rating column\n",
    "\n",
    "Final_Train['Rating'].fillna('0%', inplace=True)\n",
    "Final_Train['Rating'] = Final_Train['Rating'].str[:-1].astype(int)\n",
    "Final_Train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have replaced the mising values with -99% to differentiate them.\n",
    "# We will omit the % sign in rating column\n",
    "\n",
    "Final_Test['Rating'].fillna('0%', inplace=True)\n",
    "Final_Test['Rating'] = Final_Test['Rating'].str[:-1].astype(int)\n",
    "Final_Test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fliing the Null values in Place column with unknown, unknown\n",
    "# The place column has 2 information in it. Lets create other 2 column to contain them separately for better\n",
    "# analysis\n",
    "\n",
    "Final_Train['Place'].fillna('unknown, unknown', inplace=True)\n",
    "Final_Test['Place'].fillna('unknown, unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the data based on comma (',')\n",
    "\n",
    "Final_Train['Place'] = Final_Train['Place'].str.split(',')\n",
    "Final_Train['City'] = Final_Train['Place'].str[-1]\n",
    "Final_Train['Place'] = Final_Train['Place'].str[0]\n",
    "\n",
    "Final_Test['Place'] = Final_Test['Place'].str.split(',')\n",
    "Final_Test['City'] = Final_Test['Place'].str[-1]\n",
    "Final_Test['Place'] = Final_Test['Place'].str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Train['Qualification'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Test['Qualification'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Train['Qualification'].value_counts(normalize=True)[:20].plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Train['Qualification'] = Final_Train['Qualification'].str.split(',')\n",
    "Final_Train['Qualification'] = Final_Train['Qualification'].str[0]\n",
    "\n",
    "Final_Test['Qualification'] = Final_Test['Qualification'].str.split(',')\n",
    "Final_Test['Qualification'] = Final_Test['Qualification'].str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Train['Qualification'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Test['Qualification'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Train['Profile'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the Profile column into categorical type\n",
    "\n",
    "Final_Train.Profile = pd.Categorical(Final_Train.Profile)\n",
    "Final_Test.Profile = pd.Categorical(Final_Test.Profile)\n",
    "\n",
    "# create a new column region code\n",
    "Final_Train['Profile Code'] = Final_Train.Profile.cat.codes\n",
    "Final_Test['Profile Code'] = Final_Test.Profile.cat.codes\n",
    "\n",
    "# Drop the profile column from both the test and train dataframe\n",
    "\n",
    "Final_Train.drop(['Profile'],axis=1,inplace=True)\n",
    "Final_Test.drop(['Profile'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the City column into categorical type\n",
    "\n",
    "Final_Train.City = pd.Categorical(Final_Train.City)\n",
    "Final_Test.City = pd.Categorical(Final_Test.City)\n",
    "\n",
    "# create a new column region code\n",
    "Final_Train['city'] = Final_Train.City.cat.codes\n",
    "Final_Test['city'] = Final_Test.City.cat.codes\n",
    "\n",
    "# Drop the profile column from both the test and train dataframe\n",
    "\n",
    "Final_Train.drop(['City'],axis=1,inplace=True)\n",
    "Final_Test.drop(['City'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the Place column into categorical type\n",
    "\n",
    "Final_Train.Place = pd.Categorical(Final_Train.Place)\n",
    "Final_Test.Place = pd.Categorical(Final_Test.Place)\n",
    "\n",
    "# create a new column place\n",
    "Final_Train['place'] = Final_Train.Place.cat.codes\n",
    "Final_Test['place'] = Final_Test.Place.cat.codes\n",
    "\n",
    "# Drop the Place column from both the test and train dataframe\n",
    "\n",
    "Final_Train.drop(['Place'],axis=1,inplace=True)\n",
    "Final_Test.drop(['Place'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the Qualification column into categorical type\n",
    "\n",
    "Final_Train.Qualification = pd.Categorical(Final_Train.Qualification)\n",
    "Final_Test.Qualification = pd.Categorical(Final_Test.Qualification)\n",
    "\n",
    "# create a new column place\n",
    "Final_Train['qualification'] = Final_Train.Qualification.cat.codes\n",
    "Final_Test['qualification'] = Final_Test.Qualification.cat.codes\n",
    "\n",
    "# Drop the Qualification column from both the test and train dataframe\n",
    "\n",
    "Final_Train.drop(['Qualification'],axis=1,inplace=True)\n",
    "Final_Test.drop(['Qualification'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Miscellaneous_Info misisng values in Final_Train = \",Final_Train['Miscellaneous_Info'].isnull().sum())\n",
    "print(Final_Train['Miscellaneous_Info'].shape)\n",
    "print(\"Miscellaneous_Info misisng values in Final_Test = \",Final_Test['Miscellaneous_Info'].isnull().sum())\n",
    "print(Final_Test['Miscellaneous_Info'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since around 50% of data is missing in Miscellaneous_Info column, at this stage we will drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Train.drop(['Miscellaneous_Info'],axis=1,inplace=True)\n",
    "Final_Test.drop(['Miscellaneous_Info'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "sns.heatmap(Final_Train.corr(), annot=True, linewidths=0.5, linecolor='black', fmt='.2f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(Final_Train['Fees'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"Rating\", y=\"Fees\", data=Final_Train)\n",
    "plt.xticks(rotation=\"90\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"Experience\", y=\"Fees\", data=Final_Train)\n",
    "plt.xticks(rotation=\"90\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"Profile Code\", y=\"Fees\", data=Final_Train)\n",
    "plt.xticks(rotation=\"90\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"city\", y=\"Fees\", data=Final_Train)\n",
    "plt.xticks(rotation=\"90\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outlier checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "import numpy as np\n",
    "z=np.abs(zscore(Final_Train))\n",
    "threshold=3\n",
    "np.where(z>3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train = Final_Train[(z<3).all(axis=1)]\n",
    "print(final_train.shape)\n",
    "final_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spliting Final_Train into x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=final_train.drop(['Fees'],axis=1)\n",
    "y=pd.DataFrame(final_train['Fees'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Finding the best random state\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# #Finding the best random state\n",
    "# best_rstate=0\n",
    "# accu=0\n",
    "\n",
    "# for i in range(30,200):\n",
    "#     x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.25,random_state=i)\n",
    "#     mod=LinearRegression()\n",
    "#     mod.fit(x_train,y_train)\n",
    "#     y_pred = mod.predict(x_test)\n",
    "#     tempaccu=r2_score(y_test,y_pred)\n",
    "#     if tempaccu > accu:\n",
    "#         accu = tempaccu\n",
    "#         best_rstate = i\n",
    "        \n",
    "# print(f\"Best Accuracy {accu*100} found on Random state {best_rstate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.20, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "LR = LinearRegression()\n",
    "LR.fit(x_train,y_train)\n",
    "y_pred = LR.predict(x_test)\n",
    "\n",
    "r2score = r2_score(y_test,y_pred)\n",
    "cvscore = cross_val_score(LinearRegression(), x_train, y_train, cv=5).mean()\n",
    "\n",
    "print(f\"Accuracy= {r2score*100}, cross_val_score= {cvscore*100} & difference= {(r2score*100)-(cvscore*100)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RF = RandomForestRegressor()\n",
    "RF.fit(x_train,y_train)\n",
    "y_pred = RF.predict(x_test)\n",
    "\n",
    "r2score = r2_score(y_test,y_pred)\n",
    "cvscore = cross_val_score(RandomForestRegressor(), x_train, y_train, cv=5).mean()\n",
    "\n",
    "print(f\"Accuracy= {r2score*100}, cross_val_score= {cvscore*100} & difference= {(r2score*100)-(cvscore*100)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaboost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "ADB=AdaBoostRegressor()\n",
    "ADB.fit(x_train,y_train)\n",
    "y_pred = ADB.predict(x_test)\n",
    "\n",
    "r2score = r2_score(y_test,y_pred)\n",
    "cvscore = cross_val_score(AdaBoostRegressor(), x_train, y_train, cv=5).mean()\n",
    "\n",
    "print(f\"Accuracy= {r2score*100}, cross_val_score= {cvscore*100} & difference= {(r2score*100)-(cvscore*100)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I received a very poor accuracy with this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating parameter list to pass in GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "parameters = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "GCV = GridSearchCV(RandomForestRegressor(),parameters,cv=5,scoring='r2') # initializing GridsearchCV\n",
    "GCV.fit(x_train,y_train)\n",
    "GCV.best_estimator_   # Finding best estimators\n",
    "GCV_pred = GCV.best_estimator_.predict(x_test) #predicting the values using best estimators found by gridserchcv\n",
    "print(\"Final Accuracy: \",r2_score(y_test,GCV_pred)*100) # final accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
